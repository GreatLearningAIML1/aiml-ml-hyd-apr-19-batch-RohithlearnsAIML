{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Questions-HYD_AIML_Nov18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGIsF1ADyJ58"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-n6tVFayGBe"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cq8ejXHJyGYq"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWYbxnBayFUP",
        "colab": {}
      },
      "source": [
        "#Importing important modules\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62vUZv9m718y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "08892ee7-37b3-4e75-9072-62cfaaa9a56e"
      },
      "source": [
        "(trainX, trainY),(testX, testY) = cifar10.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FboyzCgS8a1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee799da6-090c-46f9-885c-3954e61ecdfd"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "895aSNMLF0R0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca5de9c0-20c0-40b2-8244-55b3c200e825"
      },
      "source": [
        "testX.shape[0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6QrNQP8FfYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train = []\n",
        "Y1_train = []\n",
        "X2_train = []\n",
        "Y2_train = []\n",
        "X1_test = [] \n",
        "Y1_test = []\n",
        "X2_test = []\n",
        "Y2_test = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RiLAlnN-LXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ix in range(50000):\n",
        "    if trainY[ix] < 5:\n",
        "        # put data in set 1\n",
        "        X1_train.append(trainX[ix])\n",
        "        Y1_train.append(trainY[ix])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_train.append(trainX[ix])\n",
        "        Y2_train.append(trainY[ix])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wa24CEnFsCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ix in range(testX.shape[0]):\n",
        "    if testY[ix] < 5:\n",
        "        # put data in set 1\n",
        "        X1_test.append(testX[ix])\n",
        "        Y1_test.append(testY[ix])\n",
        "    else:\n",
        "        # put data in set 2\n",
        "        X2_test.append(testX[ix])\n",
        "        Y2_test.append(testY[ix])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCuAv84_8syt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train = np.asarray(X1_train).reshape((-1, 32, 32, 3))\n",
        "X1_test = np.asarray(X1_test).reshape((-1, 32, 32, 3))\n",
        "X2_train = np.asarray(X2_train).reshape((-1, 32, 32, 3))\n",
        "X2_test = np.asarray(X2_test).reshape((-1, 32, 32, 3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhFsBwoyDnW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c120715a-f444-4c41-e9eb-7e8606fdf9c0"
      },
      "source": [
        "print(X1_train.shape)\n",
        "print(X1_test.shape)\n",
        "print(X2_train.shape)\n",
        "print(X2_test.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(25000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSBd24CeCNyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train = X1_train.astype('float32')/255\n",
        "X1_test = X1_test.astype('float32')/255\n",
        "X2_train = X2_train.astype('float32')/255\n",
        "X2_test = X2_test.astype('float32')/255\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtCKmQh4yXhT"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uN5O2kJ3yYa6",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csMrR5kUJHG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y1_train = keras.utils.to_categorical(Y1_train, 5)\n",
        "Y1_test = keras.utils.to_categorical(Y1_test, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsxM0TIgJr5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_gt5 = trainY[trainY >= 5] - 5\n",
        "y_test_gt5 = testY[testY >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGsszi6FJVZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y2_train = keras.utils.to_categorical(y_train_gt5, 5)\n",
        "Y2_test = keras.utils.to_categorical(y_test_gt5, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuOiKWfeybAl"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5HzxNbiiyoBD",
        "colab": {}
      },
      "source": [
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(32,32,3),name='conv_1'))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',name='conv_2'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25,name='drop_1'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',name='conv_3'))\n",
        "model.add(Conv2D(64, (3, 3),activation='relu',name='conv_4'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_2'))\n",
        "model.add(Dropout(0.25,name='drop_2'))\n",
        "\n",
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(512, activation='relu',name='dense_1'))\n",
        "model.add(Dropout(0.5,name='drop_3'))\n",
        "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
        "model.add(Dense(5, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtYzXxlQKTTZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "97870b68-58c4-4f95-c83b-51b605c6be3c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_1 (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv_2 (Conv2D)              (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "drop_1 (Dropout)             (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv_3 (Conv2D)              (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv_4 (Conv2D)              (None, 10, 10, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_2 (MaxPooling2D)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "drop_2 (Dropout)             (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "drop_3 (Dropout)             (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 887,845\n",
            "Trainable params: 887,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96o4bf4-KcsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "\n",
        "#To use adam optimizer for learning weights with learning rate = 0.001\n",
        "optimizer = Adam(lr=0.001)\n",
        "#Set the loss function and optimizer for the model training\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wwNPz3IKfCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "4737bce4-c631-4a99-a67b-5b53b64f6cf0"
      },
      "source": [
        "model.fit(X1_train, Y1_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=(X1_test, Y1_test))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 85s 3ms/step - loss: 1.1903 - acc: 0.4931 - val_loss: 0.9626 - val_acc: 0.6080\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 85s 3ms/step - loss: 0.9053 - acc: 0.6391 - val_loss: 0.7913 - val_acc: 0.6878\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.8109 - acc: 0.6813 - val_loss: 0.7297 - val_acc: 0.7208\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.7220 - acc: 0.7213 - val_loss: 0.7157 - val_acc: 0.7244\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.6745 - acc: 0.7439 - val_loss: 0.6362 - val_acc: 0.7586\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.6293 - acc: 0.7600 - val_loss: 0.6091 - val_acc: 0.7698\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.5891 - acc: 0.7759 - val_loss: 0.6338 - val_acc: 0.7684\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.5665 - acc: 0.7871 - val_loss: 0.5722 - val_acc: 0.7856\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 89s 4ms/step - loss: 0.5281 - acc: 0.8012 - val_loss: 0.5333 - val_acc: 0.7998\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 86s 3ms/step - loss: 0.5022 - acc: 0.8121 - val_loss: 0.5809 - val_acc: 0.7876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00b69b9198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "woTfNst_ynRG"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_VCDB3Byb1a",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(32,32,3),name='conv_1'))\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu',name='conv_2'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model2.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model2.add(Dropout(0.25,name='drop_1'))\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu',name='conv_3'))\n",
        "model2.add(Conv2D(64, (3, 3),activation='relu',name='conv_4'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2),name='max_2'))\n",
        "model2.add(Dropout(0.25,name='drop_2'))\n",
        "\n",
        "#Flatten the layer\n",
        "model2.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model2.add(Dense(512, activation='relu',name='dense_1'))\n",
        "model2.add(Dropout(0.5,name='drop_3'))\n",
        "#Add Fully Connected Layer with 10 units and activation function as 'softmax'\n",
        "model2.add(Dense(5, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGmMMr_US9Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model2.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyT0ZfPSTEr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "bc8941aa-bc17-42dd-9fa4-44542a88c27a"
      },
      "source": [
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model2.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mconv_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdrop_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv_4\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdrop_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten_5\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdrop_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense_2\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1-uUPqWpyeyX"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szHjJgDvyfCt",
        "colab": {}
      },
      "source": [
        "model2.set_weights(model.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuUaN99NTPQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.compile(loss=categorical_crossentropy,\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cjh5oDhTUSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE-8UaGOTQyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "e8389c90-6f27-41c2-bad5-6a5bb6c0c08a"
      },
      "source": [
        "#Training on the dataset\n",
        "model2.fit(X2_train, Y2_train,\n",
        "          batch_size=128,\n",
        "          epochs=15,\n",
        "          verbose=1,\n",
        "          validation_data=(X2_test, Y2_test))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 29s 1ms/step - loss: 0.7566 - acc: 0.7334 - val_loss: 0.5204 - val_acc: 0.8134\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.5595 - acc: 0.7964 - val_loss: 0.4802 - val_acc: 0.8226\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.5230 - acc: 0.8095 - val_loss: 0.4592 - val_acc: 0.8382\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4998 - acc: 0.8190 - val_loss: 0.4481 - val_acc: 0.8430\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4761 - acc: 0.8269 - val_loss: 0.4354 - val_acc: 0.8420\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4624 - acc: 0.8300 - val_loss: 0.4298 - val_acc: 0.8448\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4446 - acc: 0.8383 - val_loss: 0.4229 - val_acc: 0.8494\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4305 - acc: 0.8431 - val_loss: 0.4179 - val_acc: 0.8486\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4260 - acc: 0.8454 - val_loss: 0.4114 - val_acc: 0.8550\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4159 - acc: 0.8475 - val_loss: 0.4063 - val_acc: 0.8544\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 29s 1ms/step - loss: 0.4070 - acc: 0.8521 - val_loss: 0.4038 - val_acc: 0.8544\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3925 - acc: 0.8579 - val_loss: 0.4028 - val_acc: 0.8602\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3860 - acc: 0.8597 - val_loss: 0.3989 - val_acc: 0.8614\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 31s 1ms/step - loss: 0.3722 - acc: 0.8608 - val_loss: 0.4023 - val_acc: 0.8572\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 29s 1ms/step - loss: 0.3674 - acc: 0.8647 - val_loss: 0.3961 - val_acc: 0.8608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00b660b780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "## Sentiment analysis <br> \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### 6. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eXGIe-SH0NA",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('./tweets.csv', encoding = \"ISO-8859-1\").dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CWeWe1eJH0NF",
        "outputId": "27e0dee1-cf08-4c3b-8a30-b2aaea8f732c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7kX-WoJDH0NV",
        "outputId": "003eaabd-1e93-4914-f797-56b9edd4678d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OGWB3P2WH0NY"
      },
      "source": [
        "### Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bdgA_8N2H0NY",
        "colab": {}
      },
      "source": [
        "data = data[(data['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (data['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Jlu-reIH0Na",
        "outputId": "e5515121-c25b-4a46-c1f5-e92db1dc3bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SotCRvkDH0Nf"
      },
      "source": [
        "### 7. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
        "\n",
        "#### Use `vect` as the variable name for initialising CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YcbkY4sgH0Ng",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KyXtZGr-H0Nl",
        "colab": {}
      },
      "source": [
        "X = data.tweet_text\n",
        "y=data.is_there_an_emotion_directed_at_a_brand_or_product\n",
        "# split the new DataFrame into training and testing sets [Default test size = 25%]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z4LUM-XPH0Nn",
        "colab": {}
      },
      "source": [
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "X_test_dtm = vect.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aIdZYxJtH0Nq",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5pxd5fSHH0Nt"
      },
      "source": [
        "### 8. Find number of different words in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p1DQ2LdNH0Nu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5751faa-a3cd-406a-a01d-259d0861302a"
      },
      "source": [
        "vect.vocabulary_"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tried': 4435,\n",
              " 'installing': 2239,\n",
              " 'mention': 2721,\n",
              " 'on': 2999,\n",
              " 'my': 2858,\n",
              " 'iphone': 2291,\n",
              " 'but': 669,\n",
              " 'it': 2311,\n",
              " 'crashes': 1027,\n",
              " 'every': 1480,\n",
              " 'time': 4347,\n",
              " 'open': 3008,\n",
              " 'sxsw': 4149,\n",
              " 'ipad2': 2285,\n",
              " 'rocks': 3606,\n",
              " 'apple': 315,\n",
              " 'pop': 3244,\n",
              " 'up': 4546,\n",
              " 'store': 4044,\n",
              " 'link': 2520,\n",
              " 'what': 4722,\n",
              " 'your': 4863,\n",
              " 'take': 4191,\n",
              " 'ipad': 2283,\n",
              " 'really': 3452,\n",
              " 'want': 4671,\n",
              " 'checkins': 791,\n",
              " 'aron': 344,\n",
              " 'pilhofer': 3182,\n",
              " 'from': 1736,\n",
              " 'the': 4279,\n",
              " 'new': 2900,\n",
              " 'york': 4860,\n",
              " 'times': 4351,\n",
              " 'just': 2363,\n",
              " 'endorsed': 1418,\n",
              " 'html': 2119,\n",
              " 'over': 3054,\n",
              " 'at': 367,\n",
              " 'newsapps': 2904,\n",
              " 'and': 268,\n",
              " 'asked': 360,\n",
              " 'us': 4562,\n",
              " 'not': 2937,\n",
              " 'to': 4366,\n",
              " 'tweet': 4475,\n",
              " 'he': 2007,\n",
              " 'actually': 162,\n",
              " 'said': 3640,\n",
              " 'lt': 2595,\n",
              " 'guess': 1929,\n",
              " 'who': 4729,\n",
              " 'won': 4787,\n",
              " 'an': 265,\n",
              " 'unsix': 4538,\n",
              " 'tweetup': 4484,\n",
              " 'thanks': 4276,\n",
              " 'amp': 262,\n",
              " 'happydance': 1983,\n",
              " 'pedicab': 3137,\n",
              " 'charger': 776,\n",
              " 'would': 4816,\n",
              " 'be': 482,\n",
              " 'epic': 1448,\n",
              " 'win': 4752,\n",
              " 'data': 1109,\n",
              " 'crunch': 1059,\n",
              " 'is': 2303,\n",
              " 'crippling': 1047,\n",
              " 'google': 1873,\n",
              " 'voice': 4640,\n",
              " 'back': 428,\n",
              " 'regular': 3494,\n",
              " 'texting': 4272,\n",
              " 'we': 4694,\n",
              " 'go': 1852,\n",
              " 'got': 1884,\n",
              " 'copy': 984,\n",
              " 'of': 2975,\n",
              " 'enchantment': 1414,\n",
              " 'kindle': 2401,\n",
              " 'today': 4368,\n",
              " 'so': 3905,\n",
              " 'excited': 1499,\n",
              " 'thx': 4338,\n",
              " 'for': 1695,\n",
              " 'keeping': 2375,\n",
              " 'world': 4807,\n",
              " 'enchanted': 1412,\n",
              " 'glad': 1844,\n",
              " 'you': 4861,\n",
              " 're': 3441,\n",
              " 'again': 198,\n",
              " 'surprise': 4119,\n",
              " 'has': 1987,\n",
              " 'opened': 3011,\n",
              " 'in': 2190,\n",
              " 'austin': 391,\n",
              " 'that': 4278,\n",
              " 'nerds': 2888,\n",
              " 'town': 4405,\n",
              " 'can': 703,\n",
              " 'get': 1822,\n",
              " 'their': 4286,\n",
              " 'ipads': 2290,\n",
              " 'cnet': 858,\n",
              " 'highlight': 2048,\n",
              " 'day': 1116,\n",
              " 'was': 4680,\n",
              " 'undoubtedly': 4520,\n",
              " 'meeting': 2709,\n",
              " '30': 55,\n",
              " 'seconds': 3713,\n",
              " 'after': 196,\n",
              " 'her': 2036,\n",
              " 'softball': 3916,\n",
              " 'fancrazed': 1563,\n",
              " 'preso': 3295,\n",
              " 'quot': 3411,\n",
              " 'papyrus': 3102,\n",
              " 'sort': 3940,\n",
              " 'like': 2506,\n",
              " 'nice': 2914,\n",
              " 'lol': 2555,\n",
              " 'lavelle': 2458,\n",
              " 'smart': 3882,\n",
              " 'company': 906,\n",
              " 'set': 3755,\n",
              " 'shop': 3797,\n",
              " 'core': 989,\n",
              " 'action': 156,\n",
              " 'paper': 3101,\n",
              " 'phones': 3163,\n",
              " 'means': 2700,\n",
              " 'will': 4746,\n",
              " 'likely': 2509,\n",
              " 'useless': 4570,\n",
              " 'as': 357,\n",
              " 'well': 4715,\n",
              " 'fail': 1551,\n",
              " 'comes': 891,\n",
              " 'with': 4771,\n",
              " 'cool': 977,\n",
              " 'technology': 4238,\n",
              " 'no': 2925,\n",
              " 'one': 3001,\n",
              " 'ever': 1477,\n",
              " 'heard': 2017,\n",
              " 'because': 489,\n",
              " 'they': 4300,\n",
              " 'don': 1290,\n",
              " 'conferences': 928,\n",
              " 'via': 4609,\n",
              " 'rt': 3622,\n",
              " 'found': 1712,\n",
              " 'app': 307,\n",
              " 'kyping': 2424,\n",
              " 'geolocation': 1821,\n",
              " 'releasing': 3508,\n",
              " 'when': 4724,\n",
              " 'background': 429,\n",
              " 'need': 2879,\n",
              " 'patch': 3123,\n",
              " 'batterykiller': 474,\n",
              " 'love': 2583,\n",
              " 'frontend': 1738,\n",
              " 'dev': 1191,\n",
              " 'talk': 4201,\n",
              " 'by': 680,\n",
              " 'way': 4691,\n",
              " 'turned': 4467,\n",
              " 'head': 2008,\n",
              " 'far': 1568,\n",
              " 'could': 1002,\n",
              " 'couldn': 1003,\n",
              " 'see': 3716,\n",
              " 'single': 3839,\n",
              " 'non': 2930,\n",
              " 'device': 1198,\n",
              " 'cor': 985,\n",
              " 'ning': 2924,\n",
              " 'mobile': 2786,\n",
              " 'roadie': 3597,\n",
              " 'are': 334,\n",
              " 'thrilled': 4327,\n",
              " 'offer': 2977,\n",
              " 'unofficial': 4533,\n",
              " 'insider': 2231,\n",
              " 'guide': 1933,\n",
              " 'have': 1996,\n",
              " 'fun': 1757,\n",
              " 'downtown': 1317,\n",
              " 'hey': 2040,\n",
              " 'lucky': 2597,\n",
              " 'dogs': 1282,\n",
              " 'check': 788,\n",
              " 'out': 3046,\n",
              " 'holler': 2074,\n",
              " 'gram': 1893,\n",
              " 'plans': 3203,\n",
              " 'killing': 2398,\n",
              " 'chevytweethouse': 801,\n",
              " 'dj': 1266,\n",
              " 'willing': 4748,\n",
              " 'admit': 178,\n",
              " 'tiny': 4354,\n",
              " 'bit': 541,\n",
              " 'jealous': 2327,\n",
              " 'being': 505,\n",
              " 'bound': 593,\n",
              " 'temperatures': 4251,\n",
              " 'high': 2046,\n",
              " '20s': 41,\n",
              " 'very': 4606,\n",
              " 'hollergram': 2075,\n",
              " 'may': 2691,\n",
              " 'leave': 2472,\n",
              " 'vuvuzela': 4650,\n",
              " 'home': 2080,\n",
              " 'now': 2949,\n",
              " 'join': 2342,\n",
              " 'most': 2823,\n",
              " 'friends': 1734,\n",
              " 'ur': 4559,\n",
              " 'city': 826,\n",
              " 'end': 1415,\n",
              " 'wins': 4760,\n",
              " 'mon': 2803,\n",
              " 'help': 2031,\n",
              " 'our': 3044,\n",
              " 'chng': 808,\n",
              " 'wait': 4654,\n",
              " 'been': 493,\n",
              " 'big': 531,\n",
              " 'news': 2903,\n",
              " 'circles': 823,\n",
              " 'crazy': 1031,\n",
              " 'how': 2113,\n",
              " 'much': 2841,\n",
              " 'culture': 1068,\n",
              " 'documented': 1275,\n",
              " 'doodles': 1299,\n",
              " 'presentation': 3291,\n",
              " 'mayer': 2693,\n",
              " 'sales': 3642,\n",
              " 'pitch': 3187,\n",
              " 'rumor': 3627,\n",
              " 'opening': 3013,\n",
              " 'temporary': 4252,\n",
              " 'launch': 2453,\n",
              " 'hotpot': 2108,\n",
              " 'good': 1868,\n",
              " 'other': 3040,\n",
              " 'services': 3751,\n",
              " 'force': 1698,\n",
              " 'anyways': 299,\n",
              " 'traded': 4413,\n",
              " 'xoom': 4839,\n",
              " 'js': 2355,\n",
              " 'party': 3114,\n",
              " 'winwin': 4763,\n",
              " 'winning': 4759,\n",
              " 'tigerblood': 4342,\n",
              " 'lots': 2577,\n",
              " 'here': 2037,\n",
              " 'bigger': 532,\n",
              " 'than': 4274,\n",
              " 'thought': 4320,\n",
              " 'qrafter': 3387,\n",
              " 'better': 523,\n",
              " 'all': 238,\n",
              " 'paid': 3084,\n",
              " 'or': 3022,\n",
              " 'free': 1723,\n",
              " 'qr': 3386,\n",
              " 'code': 868,\n",
              " 'apps': 330,\n",
              " 'only': 3004,\n",
              " 'scan': 3671,\n",
              " 'vcards': 4594,\n",
              " 'also': 246,\n",
              " 'download': 1312,\n",
              " 'them': 4288,\n",
              " 'qrcode': 3389,\n",
              " 'think': 4307,\n",
              " 'eminent': 1405,\n",
              " 'typing': 4493,\n",
              " 'thoughtful': 4321,\n",
              " 'notes': 2940,\n",
              " 'phone': 3162,\n",
              " 'working': 4804,\n",
              " 'mac': 2608,\n",
              " 'book': 572,\n",
              " 'handwriting': 1971,\n",
              " 'ridic': 3578,\n",
              " 'conquered': 943,\n",
              " 'available': 406,\n",
              " 'blackberry': 545,\n",
              " 'windows': 4754,\n",
              " 'addition': 173,\n",
              " 'android': 272,\n",
              " 'line': 2516,\n",
              " 'outlandish': 3049,\n",
              " 'entire': 1440,\n",
              " 'week': 4707,\n",
              " 'looks': 2566,\n",
              " 'this': 4314,\n",
              " 'session': 3753,\n",
              " 'mistakes': 2774,\n",
              " 'made': 2618,\n",
              " 'building': 654,\n",
              " 'nextflix': 2909,\n",
              " 'might': 2747,\n",
              " 'weekend': 4708,\n",
              " 'without': 4774,\n",
              " 'seeing': 3717,\n",
              " 'same': 3645,\n",
              " 'case': 728,\n",
              " 'twice': 4485,\n",
              " 'wowwwwww': 4819,\n",
              " 'next': 2908,\n",
              " 'maps': 2657,\n",
              " 'amazing': 253,\n",
              " 'ready': 3446,\n",
              " 'some': 3926,\n",
              " 'make': 2634,\n",
              " 'blogging': 557,\n",
              " 'easier': 1371,\n",
              " 'sxswi': 4159,\n",
              " 'someone': 3929,\n",
              " 'buy': 674,\n",
              " 'v1': 4583,\n",
              " 'while': 4727,\n",
              " 'v2': 4584,\n",
              " 'tomorrow': 4372,\n",
              " 'potential': 3264,\n",
              " 'breakout': 618,\n",
              " 'gadgets': 1773,\n",
              " 'festival': 1610,\n",
              " 'begins': 499,\n",
              " 'jeez': 2331,\n",
              " 'guys': 1941,\n",
              " 'dunno': 1351,\n",
              " 'about': 132,\n",
              " 'gold': 1864,\n",
              " 'gym': 1943,\n",
              " 'do': 1271,\n",
              " 'realize': 3450,\n",
              " 'un': 4507,\n",
              " 'jobs': 2339,\n",
              " 'aesthetic': 192,\n",
              " 'strong': 4065,\n",
              " 'rumours': 3630,\n",
              " 'abt': 136,\n",
              " 'unveiling': 4544,\n",
              " 'social': 3907,\n",
              " 'network': 2895,\n",
              " 'called': 692,\n",
              " 'does': 1279,\n",
              " 'look': 2561,\n",
              " 'interesting': 2255,\n",
              " 'long': 2558,\n",
              " 'into': 2263,\n",
              " 'aclu': 152,\n",
              " 'sure': 4115,\n",
              " 'ûï': 4907,\n",
              " 'last': 2441,\n",
              " 'lp': 2594,\n",
              " 'travel': 4425,\n",
              " 'tougher': 4402,\n",
              " 'crowd': 1053,\n",
              " 'colin': 877,\n",
              " 'quinn': 3408,\n",
              " 'marissa': 2664,\n",
              " 'please': 3217,\n",
              " 'tell': 4247,\n",
              " 'something': 3931,\n",
              " 'products': 3322,\n",
              " 'launched': 2454,\n",
              " 'months': 2813,\n",
              " 'ago': 207,\n",
              " 'awesome': 418,\n",
              " 'hear': 2016,\n",
              " 'acknowledge': 151,\n",
              " 'needs': 2881,\n",
              " 'increase': 2200,\n",
              " 'support': 4112,\n",
              " 'its': 2312,\n",
              " 'product': 3321,\n",
              " 'incorrect': 2199,\n",
              " 'routes': 3615,\n",
              " 'chrome': 816,\n",
              " 'web': 4698,\n",
              " 'calls': 694,\n",
              " 'html5': 2120,\n",
              " 'hot': 2105,\n",
              " 'tub': 4457,\n",
              " 'steamy': 4024,\n",
              " 'suck': 4090,\n",
              " 'preview': 3301,\n",
              " 'major': 2632,\n",
              " 'service': 3750,\n",
              " 'diller': 1224,\n",
              " 'says': 3668,\n",
              " 'tv': 4470,\n",
              " 'run': 3631,\n",
              " 'playstation': 3215,\n",
              " 'xbox': 4834,\n",
              " 'which': 4726,\n",
              " 'essentially': 1460,\n",
              " 'more': 2818,\n",
              " 'fees': 1601,\n",
              " 'booyah': 579,\n",
              " 'gitchococktailon': 1838,\n",
              " 'before': 495,\n",
              " 'even': 1470,\n",
              " 'past': 3121,\n",
              " 'there': 4296,\n",
              " 'dilemma': 1223,\n",
              " 'tech': 4228,\n",
              " 'come': 888,\n",
              " 'why': 4735,\n",
              " 'cant': 708,\n",
              " 'spell': 3964,\n",
              " 'checking': 790,\n",
              " 'auto': 401,\n",
              " 'correct': 994,\n",
              " 'must': 2854,\n",
              " 'nothing': 2942,\n",
              " 'grrr': 1920,\n",
              " 'holy': 2078,\n",
              " 'smokes': 3892,\n",
              " 'replacing': 3524,\n",
              " 'flip': 1662,\n",
              " 'cam': 696,\n",
              " 'default': 1139,\n",
              " 'video': 4615,\n",
              " 'capture': 713,\n",
              " 'beautiful': 486,\n",
              " 'elegant': 1396,\n",
              " 'know': 2414,\n",
              " 'started': 4007,\n",
              " 'lying': 2606,\n",
              " 'me': 2698,\n",
              " 'signal': 3826,\n",
              " 'strength': 4060,\n",
              " 'def': 1138,\n",
              " 'use': 4566,\n",
              " 'tweeting': 4482,\n",
              " 'sorta': 3941,\n",
              " 'pretty': 3299,\n",
              " 'sux': 4128,\n",
              " 'airport': 223,\n",
              " 'delay': 1146,\n",
              " 'introduced': 2267,\n",
              " 'catphysics': 736,\n",
              " 'feel': 1596,\n",
              " 'drug': 1340,\n",
              " 'pusher': 3376,\n",
              " 'first': 1643,\n",
              " 'play': 3208,\n",
              " 'hollrback': 2076,\n",
              " 'released': 3506,\n",
              " 'users': 4572,\n",
              " 'grab': 1891,\n",
              " 'com': 884,\n",
              " 'watching': 4686,\n",
              " 'advanced': 187,\n",
              " 'future': 1762,\n",
              " 'location': 2546,\n",
              " 'based': 463,\n",
              " 'augmented': 388,\n",
              " 'reality': 3449,\n",
              " 'projects': 3333,\n",
              " 'congrats': 934,\n",
              " 'sxswbuffalo': 4155,\n",
              " 'lounge': 2581,\n",
              " 'experience': 1518,\n",
              " 'complete': 915,\n",
              " 'quibidswin': 3403,\n",
              " 'cursor': 1075,\n",
              " 'connects': 942,\n",
              " 'physical': 3168,\n",
              " 'digital': 1221,\n",
              " 'worlds': 4808,\n",
              " 'mystery': 2864,\n",
              " 'prize': 3313,\n",
              " 'hope': 2095,\n",
              " 'great': 1901,\n",
              " 'panel': 3092,\n",
              " 'gift': 1830,\n",
              " 'discotalk': 1241,\n",
              " 'ordered': 3025,\n",
              " 'stand': 3996,\n",
              " 'wasting': 4683,\n",
              " 'valuable': 4589,\n",
              " 'fellowship': 1604,\n",
              " 'dear': 1125,\n",
              " 'goer': 1857,\n",
              " 'fucking': 1750,\n",
              " 'walking': 4662,\n",
              " 'halls': 1962,\n",
              " 'hipsters': 2058,\n",
              " 'hilarious': 2052,\n",
              " 'client': 842,\n",
              " 'gotten': 1886,\n",
              " 'buggy': 651,\n",
              " 'lately': 2444,\n",
              " 'blame': 547,\n",
              " 'putting': 3380,\n",
              " 'gun': 1937,\n",
              " 'give': 1839,\n",
              " 'oh': 2989,\n",
              " 'lordy': 2570,\n",
              " 'pulling': 3363,\n",
              " 'trigger': 4437,\n",
              " 'futuremf': 1763,\n",
              " 'trajan': 4418,\n",
              " 'destroyed': 1186,\n",
              " 'title': 4357,\n",
              " 'gt': 1926,\n",
              " 'tag': 4189,\n",
              " 'websites': 4704,\n",
              " 'seo': 3739,\n",
              " 'graph': 1897,\n",
              " 'protocol': 3346,\n",
              " 'added': 168,\n",
              " 'clean': 836,\n",
              " 'instead': 2243,\n",
              " 'umm': 4504,\n",
              " 'hello': 2030,\n",
              " 'version': 4604,\n",
              " 'site': 3846,\n",
              " 'coming': 894,\n",
              " 'miller': 2752,\n",
              " 'makes': 2636,\n",
              " 'shout': 3809,\n",
              " 'khan': 2384,\n",
              " 'academy': 138,\n",
              " 'things': 4305,\n",
              " 'doing': 1283,\n",
              " 'education': 1384,\n",
              " 'fmsignal': 1674,\n",
              " 'cc': 742,\n",
              " 'turn': 4466,\n",
              " 'messaging': 2727,\n",
              " 'platform': 3207,\n",
              " 'cheeky': 793,\n",
              " 'built': 656,\n",
              " 'resist': 3537,\n",
              " 'buying': 676,\n",
              " 'notionink': 2944,\n",
              " 'adam': 164,\n",
              " 'able': 131,\n",
              " 'usb': 4565,\n",
              " 'charging': 780,\n",
              " 'cord': 986,\n",
              " 'plug': 3222,\n",
              " 'add': 167,\n",
              " 'juice': 2357,\n",
              " 'dfw': 1204,\n",
              " 'texas': 4270,\n",
              " 'entry': 1443,\n",
              " 'received': 3461,\n",
              " 'anti': 285,\n",
              " 'privacy': 3311,\n",
              " 'law': 2459,\n",
              " 'petition': 3157,\n",
              " 'sunglasses': 4106,\n",
              " 'beer': 494,\n",
              " 'geo': 1819,\n",
              " 'mixing': 2778,\n",
              " 'music': 2848,\n",
              " 'parties': 3109,\n",
              " 'going': 1863,\n",
              " 'year': 4848,\n",
              " 'trying': 4452,\n",
              " 'steve': 4030,\n",
              " 'wozniak': 4820,\n",
              " 'drink': 1327,\n",
              " 'h4ckers': 1946,\n",
              " 'speakeasy': 3957,\n",
              " 'doesn': 1280,\n",
              " 'too': 4378,\n",
              " 'bad': 434,\n",
              " 'waited': 4655,\n",
              " 'hours': 2111,\n",
              " 'likability': 2505,\n",
              " 'virgin': 4626,\n",
              " 'trustworthiness': 4449,\n",
              " 'zappos': 4874,\n",
              " 'pnid': 3228,\n",
              " 'beta': 521,\n",
              " 'testing': 4266,\n",
              " 'interactive': 2253,\n",
              " 'moonbot': 2816,\n",
              " 'studios': 4072,\n",
              " 'louisiana': 2580,\n",
              " 'listening': 2527,\n",
              " 'twit': 4486,\n",
              " 'live': 2530,\n",
              " 'went': 4716,\n",
              " 'boxee': 598,\n",
              " 'keg': 2376,\n",
              " 'robots': 3600,\n",
              " 'event': 1472,\n",
              " 'saw': 3665,\n",
              " 'tim': 4345,\n",
              " 'ferris': 1606,\n",
              " 'speak': 3956,\n",
              " 'checked': 789,\n",
              " 'ebay': 1377,\n",
              " 'hackathon': 1950,\n",
              " 'hmm': 2068,\n",
              " 'interface': 2256,\n",
              " 'ux': 4580,\n",
              " 'research': 3535,\n",
              " 'sound': 3943,\n",
              " 'politics': 3237,\n",
              " 'behind': 504,\n",
              " 'applauds': 314,\n",
              " 'anyone': 295,\n",
              " '10': 3,\n",
              " 'dangerous': 1102,\n",
              " 'giving': 1843,\n",
              " 'away': 417,\n",
              " 'creator': 1041,\n",
              " 'popular': 3249,\n",
              " 'disc': 1240,\n",
              " 'during': 1353,\n",
              " 'create': 1035,\n",
              " 'share': 3772,\n",
              " 'twitter': 4487,\n",
              " 'outlet': 3050,\n",
              " 'another': 282,\n",
              " 'example': 1493,\n",
              " 'marketing': 2671,\n",
              " 'brilliance': 627,\n",
              " 'art': 349,\n",
              " 'project': 3330,\n",
              " 'street': 4058,\n",
              " 'view': 4620,\n",
              " 'except': 1496,\n",
              " 'museums': 2847,\n",
              " 'around': 345,\n",
              " 'incl': 2194,\n",
              " 'billion': 535,\n",
              " 'pixel': 3190,\n",
              " 'image': 2163,\n",
              " 'starry': 4004,\n",
              " 'night': 2919,\n",
              " 'dang': 1101,\n",
              " 'whoooooo': 4732,\n",
              " 'ps': 3352,\n",
              " 'tvontheradio': 4472,\n",
              " 'tix': 4359,\n",
              " 'yall': 4843,\n",
              " 'rock': 3601,\n",
              " 'right': 3583,\n",
              " 'had': 1954,\n",
              " 'improve': 2182,\n",
              " '15': 21,\n",
              " 'minutes': 2767,\n",
              " 'literally': 2528,\n",
              " 'bumped': 660,\n",
              " 'thinking': 4308,\n",
              " 'should': 3805,\n",
              " 'lottery': 2578,\n",
              " 'ticket': 4339,\n",
              " 'kind': 2399,\n",
              " 'funny': 1760,\n",
              " 'sad': 3637,\n",
              " 'release': 3505,\n",
              " 'longer': 2559,\n",
              " 'any': 292,\n",
              " 'lines': 2517,\n",
              " 'sheeple': 3780,\n",
              " 'several': 3762,\n",
              " 'years': 4849,\n",
              " 'late': 2443,\n",
              " 'trend': 4431,\n",
              " 'conversation': 972,\n",
              " 'laughed': 2452,\n",
              " 'until': 4541,\n",
              " 'spent': 3967,\n",
              " 'hauling': 1995,\n",
              " 'macbook': 2610,\n",
              " 'everywhere': 1486,\n",
              " 'shoulder': 3807,\n",
              " 'rub': 3623,\n",
              " 'kawasaki': 2372,\n",
              " 'pagemaker': 3082,\n",
              " 'saved': 3659,\n",
              " 'those': 4318,\n",
              " 'were': 4717,\n",
              " 'days': 1118,\n",
              " 'jwtatl': 2367,\n",
              " 'kids': 2392,\n",
              " 'the_daily': 4280,\n",
              " 'terrible': 4263,\n",
              " 'concept': 923,\n",
              " 'anyway': 298,\n",
              " 'many': 2651,\n",
              " 'publishers': 3360,\n",
              " 'content': 957,\n",
              " 'enhancements': 1428,\n",
              " 'th': 4273,\n",
              " 'worst': 4812,\n",
              " 'david': 1112,\n",
              " 'foster': 1711,\n",
              " 'wallace': 4665,\n",
              " 'footnotes': 1694,\n",
              " 'kinda': 2400,\n",
              " 'mostly': 2824,\n",
              " 'irrelevant': 2302,\n",
              " 'white': 4728,\n",
              " '64gb': 94,\n",
              " 'wifi': 4741,\n",
              " 'blue': 562,\n",
              " 'cover': 1010,\n",
              " 'thing': 4304,\n",
              " 'sell': 3731,\n",
              " 'mappers': 2654,\n",
              " 'amazingly': 254,\n",
              " 'easy': 1372,\n",
              " 'details': 1189,\n",
              " 'domo': 1289,\n",
              " 'facebook': 1543,\n",
              " 'strangers': 4052,\n",
              " 'didn': 1209,\n",
              " 'airs': 225,\n",
              " 'did': 1208,\n",
              " 'read': 3442,\n",
              " 'where': 4725,\n",
              " 'keynote': 2382,\n",
              " 'mayers': 2694,\n",
              " '12': 15,\n",
              " 'miles': 2749,\n",
              " 'driven': 1330,\n",
              " 'navigation': 2873,\n",
              " 'yr': 4867,\n",
              " 'route': 3614,\n",
              " 'traffic': 4415,\n",
              " 'saving': 3662,\n",
              " 'yrs': 4868,\n",
              " 'total': 4394,\n",
              " 'wow': 4818,\n",
              " 'possibly': 3261,\n",
              " 'super': 4109,\n",
              " 'celebrate': 743,\n",
              " 'charity': 781,\n",
              " 'water': 4687,\n",
              " 'tonight': 4376,\n",
              " 'throwin': 4331,\n",
              " 'jump': 2362,\n",
              " 'start': 4006,\n",
              " 'off': 2976,\n",
              " 'studentsforcleanwater': 4070,\n",
              " 'org': 3028,\n",
              " 'rsvp': 3621,\n",
              " 'interview': 2261,\n",
              " 'bloomberg': 560,\n",
              " 'kick': 2386,\n",
              " 'tons': 4377,\n",
              " 'ipad2s': 2286,\n",
              " 'took': 4379,\n",
              " 'through': 4328,\n",
              " 'pics': 3175,\n",
              " 'already': 245,\n",
              " 'gowalla': 1889,\n",
              " 'pull': 3362,\n",
              " 'website': 4703,\n",
              " 'wasted': 4682,\n",
              " 'festivalgenius': 1612,\n",
              " 'notsomuch': 2946,\n",
              " 'lost': 2575,\n",
              " 'caring': 721,\n",
              " 'business': 666,\n",
              " 'reilly': 3498,\n",
              " 'whale': 4721,\n",
              " 'artist': 352,\n",
              " 'living': 2535,\n",
              " 'crowley': 1058,\n",
              " 'hard': 1984,\n",
              " 'feelings': 1599,\n",
              " 'towards': 4404,\n",
              " 'dodgeball': 1277,\n",
              " 'partner': 3110,\n",
              " 'envy': 1447,\n",
              " 'greater': 1902,\n",
              " 'waaaaaa': 4652,\n",
              " 'drivers': 1331,\n",
              " 'per': 3143,\n",
              " 'finding': 1637,\n",
              " 'best': 517,\n",
              " 'setting': 3758,\n",
              " 'attendees': 377,\n",
              " 'fix': 1651,\n",
              " 'security': 3715,\n",
              " 'guards': 1928,\n",
              " 'enjoy': 1429,\n",
              " 'sleepy': 3864,\n",
              " 'debating': 1127,\n",
              " 'brands': 609,\n",
              " 'role': 3608,\n",
              " 'enjoyed': 1430,\n",
              " 'doodle': 1298,\n",
              " 'australian': 396,\n",
              " 'profits': 3325,\n",
              " 'interested': 2254,\n",
              " 'these': 4298,\n",
              " 'insights': 2235,\n",
              " 'bing': 537,\n",
              " 'digibiz': 1220,\n",
              " 'bout': 595,\n",
              " 'watch': 4684,\n",
              " 'vicariously': 4612,\n",
              " 'popupstore': 3252,\n",
              " 'crack': 1018,\n",
              " 'house': 2112,\n",
              " 'addicts': 171,\n",
              " 'imagine': 2164,\n",
              " 'if': 2151,\n",
              " '20': 36,\n",
              " 'bavcid': 476,\n",
              " 'uppward': 4555,\n",
              " 'tshirt': 4454,\n",
              " 'clever': 840,\n",
              " 'design': 1176,\n",
              " 'jerk': 2333,\n",
              " 'faulty': 1581,\n",
              " 'autocorrect': 402,\n",
              " 'change': 766,\n",
              " 'coworkers': 1015,\n",
              " 'visigoths': 4631,\n",
              " 'five': 1648,\n",
              " 'guard': 1927,\n",
              " 'popup': 3251,\n",
              " 'loves': 2589,\n",
              " 'debut': 1128,\n",
              " 'eatdrinktweet': 1374,\n",
              " 'done': 1294,\n",
              " 'yet': 4857,\n",
              " 'mark': 2668,\n",
              " 'sleep': 3863,\n",
              " 'bring': 629,\n",
              " 'shiny': 3787,\n",
              " 'ya': 4842,\n",
              " 'takes': 4195,\n",
              " 'playhopskoch': 3213,\n",
              " 'market': 2669,\n",
              " 'getting': 1825,\n",
              " 'gps': 1890,\n",
              " 'stuck': 4069,\n",
              " 'updates': 4550,\n",
              " 'foursquare': 1714,\n",
              " 'random': 3426,\n",
              " 'exclusive': 1502,\n",
              " 'shot': 3803,\n",
              " 'tt': 4456,\n",
              " 'ff': 1615,\n",
              " 'fuck': 1749,\n",
              " 'ubersocial': 4497,\n",
              " 'includes': 2197,\n",
              " 'uberguide': 4496,\n",
              " 'post': 3262,\n",
              " 'll': 2536,\n",
              " 'using': 4575,\n",
              " 'south': 3948,\n",
              " 'southwest': 3950,\n",
              " 'verizon': 4602,\n",
              " 'kicking': 2388,\n",
              " 'hairy': 1957,\n",
              " 'butts': 673,\n",
              " 'people': 3142,\n",
              " 'qho': 3385,\n",
              " 'feature': 1588,\n",
              " 'buzz': 678,\n",
              " 'wish': 4769,\n",
              " 'beforetwitter': 496,\n",
              " 'wouldn': 4817,\n",
              " 'such': 4089,\n",
              " 'haha': 1956,\n",
              " 'awesomely': 419,\n",
              " 'rad': 3413,\n",
              " 'map': 2652,\n",
              " 'saves': 3660,\n",
              " 'drive': 1329,\n",
              " 'missed': 2771,\n",
              " 'amount': 261,\n",
              " 'gas': 1788,\n",
              " 'belinsky': 507,\n",
              " '911tweets': 114,\n",
              " 'lonely': 2556,\n",
              " 'planet': 3200,\n",
              " 'releases': 3507,\n",
              " 'aren': 337,\n",
              " 'enough': 1434,\n",
              " 'cluttering': 854,\n",
              " 'handset': 1970,\n",
              " 'part': 3107,\n",
              " 'journalsim': 2350,\n",
              " 'democracy': 1163,\n",
              " 'yes': 4855,\n",
              " 'informed': 2215,\n",
              " 'populous': 3250,\n",
              " 'focus': 1675,\n",
              " 'informal': 2213,\n",
              " 'unscientific': 4537,\n",
              " 'observation': 2966,\n",
              " 'computer': 919,\n",
              " 'choice': 809,\n",
              " 'hands': 1969,\n",
              " 'instagram': 2236,\n",
              " 'moment': 2799,\n",
              " 'mister': 2775,\n",
              " 'different': 1217,\n",
              " 'evo': 1489,\n",
              " 'sucks': 4092,\n",
              " 'decided': 1133,\n",
              " 'usguys': 4574,\n",
              " 'woot': 4796,\n",
              " 'ausxsw': 397,\n",
              " 'shame': 3769,\n",
              " 'schools': 3687,\n",
              " 'experts': 1523,\n",
              " 'official': 2982,\n",
              " 'photos': 3167,\n",
              " 'weird': 4712,\n",
              " 'focusing': 1677,\n",
              " 'bridging': 623,\n",
              " 'divide': 1265,\n",
              " 'eg': 1390,\n",
              " 'streetview': 4059,\n",
              " 'autonomous': 404,\n",
              " 'driving': 1333,\n",
              " 'cow': 1013,\n",
              " 'hooked': 2088,\n",
              " 'paolo': 3098,\n",
              " 'alex': 236,\n",
              " 'backup': 432,\n",
              " 'powermat': 3271,\n",
              " 'powermatteam': 3272,\n",
              " 'gonna': 1867,\n",
              " 'bet': 520,\n",
              " 'que': 3397,\n",
              " 'looking': 2564,\n",
              " 'distribution': 1261,\n",
              " 'enchanting': 1413,\n",
              " 'likeability': 2507,\n",
              " 'airlines': 221,\n",
              " 'ha': 1947,\n",
              " 'guy': 1939,\n",
              " 'explaining': 1525,\n",
              " 'realistic': 3448,\n",
              " 'bots': 589,\n",
              " 'experiment': 1520,\n",
              " 'gee': 1797,\n",
              " 'fell': 1602,\n",
              " 'throwing': 4332,\n",
              " 'nerd': 2883,\n",
              " '3d': 66,\n",
              " 'buildings': 655,\n",
              " 'fast': 1576,\n",
              " 'rendering': 3521,\n",
              " 'own': 3069,\n",
              " 'find': 1635,\n",
              " 'impromptu': 2181,\n",
              " 'til': 4343,\n",
              " 'josh': 2348,\n",
              " 'williams': 4747,\n",
              " 'farmville': 1571,\n",
              " 'success': 4086,\n",
              " 'wakeup': 4657,\n",
              " 'call': 689,\n",
              " 'games': 1782,\n",
              " 'build': 653,\n",
              " 'lose': 2572,\n",
              " 'hour': 2110,\n",
              " 'microsoft': 2739,\n",
              " 'credit': 1042,\n",
              " 'fixing': 1652,\n",
              " 'christmas': 815,\n",
              " 'arm': 342,\n",
              " 'giant': 1827,\n",
              " 'meat': 2704,\n",
              " 'pointer': 3233,\n",
              " 'disgusted': 1250,\n",
              " 'battery': 473,\n",
              " 'life': 2497,\n",
              " 'down': 1311,\n",
              " '11': 12,\n",
              " 'pm': 3227,\n",
              " 'geeky': 1810,\n",
              " 'refrigerator': 3486,\n",
              " 'magnet': 2628,\n",
              " 'game': 1779,\n",
              " 'everyone': 1483,\n",
              " 'stops': 4042,\n",
              " 've': 4595,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwtgjTBeH0Ny"
      },
      "source": [
        "#### Tip: To see all available functions for an Object use dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2n_iCcTNH0N0",
        "outputId": "9b55a8a0-68c4-46b0-e3c3-71c95ba16da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(vect)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_char_ngrams',\n",
              " '_char_wb_ngrams',\n",
              " '_check_stop_words_consistency',\n",
              " '_check_vocabulary',\n",
              " '_count_vocab',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_limit_features',\n",
              " '_more_tags',\n",
              " '_sort_features',\n",
              " '_stop_words_id',\n",
              " '_validate_custom_analyzer',\n",
              " '_validate_params',\n",
              " '_validate_vocabulary',\n",
              " '_white_spaces',\n",
              " '_word_ngrams',\n",
              " 'analyzer',\n",
              " 'binary',\n",
              " 'build_analyzer',\n",
              " 'build_preprocessor',\n",
              " 'build_tokenizer',\n",
              " 'decode',\n",
              " 'decode_error',\n",
              " 'dtype',\n",
              " 'encoding',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'fixed_vocabulary_',\n",
              " 'get_feature_names',\n",
              " 'get_params',\n",
              " 'get_stop_words',\n",
              " 'input',\n",
              " 'inverse_transform',\n",
              " 'lowercase',\n",
              " 'max_df',\n",
              " 'max_features',\n",
              " 'min_df',\n",
              " 'ngram_range',\n",
              " 'preprocessor',\n",
              " 'set_params',\n",
              " 'stop_words',\n",
              " 'stop_words_',\n",
              " 'strip_accents',\n",
              " 'token_pattern',\n",
              " 'tokenizer',\n",
              " 'transform',\n",
              " 'vocabulary',\n",
              " 'vocabulary_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShA6D8jKH0N5"
      },
      "source": [
        "### Find out how many Positive and Negative emotions are there.\n",
        "\n",
        "Hint: Use value_counts on that column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7LAl5pzH0N6",
        "outputId": "dac6b73e-effa-47a4-a87b-4829f38a0bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "pd.value_counts(data['is_there_an_emotion_directed_at_a_brand_or_product'])"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2672\n",
              "Negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUvgj0FoH0N9"
      },
      "source": [
        "###  Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'label'\n",
        "\n",
        "Hint: use map on that column and give labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {}
      },
      "source": [
        "data['label'] = data.is_there_an_emotion_directed_at_a_brand_or_product.map({'Positive emotion':1, 'Negative emotion':0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### 9. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "X = data.tweet_text\n",
        "y=data.label\n",
        "# split the new DataFrame into training and testing sets [Default test size = 25%]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q5nlCuaaH0OD"
      },
      "source": [
        "## 10. **Predicting the sentiment:**\n",
        "\n",
        "\n",
        "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sw-0B33tH0Ox"
      },
      "source": [
        "## 11. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "okCTOs1TH0Oy",
        "colab": {}
      },
      "source": [
        "def tokenize_test(vect):\n",
        "    x_train_dtm = vect.fit_transform(X_train)\n",
        "    print('Features: ', x_train_dtm.shape[1])\n",
        "    x_test_dtm = vect.transform(X_test)\n",
        "    nb = MultinomialNB()\n",
        "    nb.fit(x_train_dtm, y_train)\n",
        "    y_pred_class = nb.predict(x_test_dtm)\n",
        "    print('muLTINOMIAL Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))\n",
        "    logreg=LogisticRegression()\n",
        "    logreg.fit(x_train_dtm, y_train)\n",
        "    y_pred_class = logreg.predict(x_test_dtm)\n",
        "    print('Logistic Test Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JxZ8jfPEH0O0"
      },
      "source": [
        "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kdCyAN_IH0O0",
        "outputId": "dd4c5717-8933-4738-9f2e-e86f38dbf323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# include 1-grams and 2-grams\n",
        "vect = CountVectorizer(ngram_range=(1, 2))\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  24855\n",
            "muLTINOMIAL Test Accuracy:  0.8558897243107769\n",
            "Logistic Test Accuracy:  0.8659147869674185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "axepytmgH0O4"
      },
      "source": [
        "### 12. Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6abf84d7-6bf4-40b5-99bd-c16ff90c0458",
        "id": "7Kt6W1LEZ1Xm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# include 1-grams and 2-grams\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  4681\n",
            "muLTINOMIAL Test Accuracy:  0.8533834586466166\n",
            "Logistic Test Accuracy:  0.8671679197994987\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iOIlJRxoH0O7"
      },
      "source": [
        "### 13. Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fUhff-oH0O8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1443add6-382a-4600-b1f6-2179145d9993"
      },
      "source": [
        "vect = CountVectorizer(stop_words='english',max_features=300)\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  300\n",
            "muLTINOMIAL Test Accuracy:  0.8107769423558897\n",
            "Logistic Test Accuracy:  0.8333333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2KZNWVkH0PA"
      },
      "source": [
        "### 14. Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3v9XD082H0PB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "540bbf59-0189-4300-96d3-6507dec3f80c"
      },
      "source": [
        "vect = CountVectorizer(stop_words='english',ngram_range=(1, 2),max_features=15000)\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  15000\n",
            "muLTINOMIAL Test Accuracy:  0.8558897243107769\n",
            "Logistic Test Accuracy:  0.8659147869674185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We3JK_SRH0PO"
      },
      "source": [
        "### 15. Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUHrfDCyH0PP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9a58a693-94e9-4194-cea9-c00c85987d40"
      },
      "source": [
        "vect = CountVectorizer(stop_words='english',ngram_range=(1, 2),min_df=2)\n",
        "tokenize_test(vect)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features:  5451\n",
            "muLTINOMIAL Test Accuracy:  0.8659147869674185\n",
            "Logistic Test Accuracy:  0.8671679197994987\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}